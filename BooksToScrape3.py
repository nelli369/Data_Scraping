# -*- coding: utf-8 -*-
"""DS hmk2 pr3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16q0T7UI1N82myYQ1iyOyCiLJKZ5j-pM_
"""

!pip install scrapy

import time
import requests
import numpy as np
import pandas as pd
from scrapy.http import TextResponse

import re

def books_scraper(url,base_url="http://books.toscrape.com/"):
    page = requests.get(url)
    response = TextResponse(body=page.text,url=url,encoding="utf-8")
    title = response.css("h3 > a::attr(title)").extract()
    price_l = response.css("p.price_color::text").extract()
    price = [i.replace("A", "") for i in price_l]
    book_url = response.css("h3 >a::attr(href)").extract()
    picture_url = response.css("img::attr(src)").extract()
    star = response.css("p[class^='star-rating']::attr(class)").extract()
    star_rating = []
    for i in star:
        star_rating.append(i.replace("star-rating", ""))
    stock  =response.css("p.price_color ~ p[class^='instock']::attr(class)").extract()
    instock = [i.replace("availability", " ") for i in stock]    
    base_url = "http://books.toscrape.com/catalogue/"
    bookurl = [base_url + i for i in  book_url]
    picurl = [base_url + i for i in picture_url]
    return pd.DataFrame({"Title":title,  "Price":price, "Book_urls":bookurl, "Image_urls":picurl,"Star_Rating":star_rating,"Instock":instock})

books = []
for i in range(1,1000):
    pages =books_scraper(url = f"http://books.toscrape.com/catalogue/page-{i}.html")
    if  pages.shape[0] == 0:
        break
    else:
        books.append(pages)

books = pd.concat(books)
books

